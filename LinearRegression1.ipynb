{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
      "0    1.191261 -0.308960  0.675137 -1.460501  0.053059 -1.886129  2.710794   \n",
      "1    1.071476 -1.424766 -1.109750 -0.457677  0.399997  1.587401 -1.547570   \n",
      "2   -0.045929  1.868603 -0.016568 -0.484258  1.089905 -1.147160  0.590744   \n",
      "3   -1.487154  2.220322  0.718332  1.682888 -0.420986 -0.054746  1.900832   \n",
      "4    0.344054  0.657763  0.348342 -0.417430 -0.589112  1.057814 -0.487705   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "995 -1.422254  0.576557 -0.646573 -0.756351 -0.127918  1.119575  1.687142   \n",
      "996  0.190500 -0.132634  0.709452  0.331980 -2.172670 -0.120381  0.513106   \n",
      "997 -0.326648 -0.062894  2.002427 -0.650657  1.592964 -0.395284  0.360226   \n",
      "998 -1.574342 -1.610263  0.407690  1.149487  1.466442 -0.338669 -2.059160   \n",
      "999  0.331964 -0.159202  0.510099 -0.586971  0.133761  2.344054  0.166339   \n",
      "\n",
      "        col_7     col_8     col_9    col_10    col_11    col_12    col_13  \n",
      "0   -1.716033  0.865290  0.138078 -0.063745 -2.104583 -0.476876  1.677116  \n",
      "1    0.323247  0.165859 -0.302097  0.203944 -0.212452  0.836991  0.368498  \n",
      "2    0.683325 -0.571184 -0.802199 -0.220114  0.034808  0.043829  0.955803  \n",
      "3   -0.101198  0.090042 -0.202924  0.340865  0.606237 -0.037008 -0.841048  \n",
      "4   -0.897830 -0.935596 -1.186993  1.074333 -0.069532 -0.177918 -0.912811  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "995 -1.081548 -0.955540  3.078881  0.881640  0.311250 -1.606446  0.203464  \n",
      "996 -0.435486  0.847422  1.107081 -0.259547 -0.974529 -0.535328 -0.090533  \n",
      "997 -0.307571  1.465211  0.658143  0.541321 -0.447878 -0.891543  0.069704  \n",
      "998  0.581000 -1.409216 -1.082018  0.798501  0.753190 -1.532598  0.269306  \n",
      "999 -0.572586  1.061785 -0.179530  1.236205  1.012943  0.805240 -0.036447  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(\n",
    "    n_samples=1000, n_features=14, n_informative=10, noise=15, random_state=42\n",
    ")\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "X.columns = [f\"col_{col}\" for col in X.columns]\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 20621.089638778492\n",
      "1 | loss: 13360.32856215382\n",
      "2 | loss: 8710.524708403194\n",
      "3 | loss: 5723.561711468144\n",
      "4 | loss: 3798.8486372881334\n",
      "5 | loss: 2554.79589505409\n",
      "6 | loss: 1748.2271233241017\n",
      "7 | loss: 1223.7041763294312\n",
      "8 | loss: 881.5701534679752\n",
      "9 | loss: 657.7379735877852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(26.678650591580126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLineReg:\n",
    "    def __init__(self, n_iter, learning_rate):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "        )\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
    "        #X.insert(0, 'ones', 1) #дополнение вектора фичей единичным столбцом\n",
    "        W = np.ones(X.shape[1]) #инициализация вектора весов соответствующей длины\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            y_hat = np.dot(X, W) #вычисление предсказаний\n",
    "            MSE = np.sum((y_hat - y) ** 2) / len(y) #вычисление функции потерь (в данном случае MSE)\n",
    "            \n",
    "            if verbose:\n",
    "                if i == 0:\n",
    "                    print(f'start | loss: {MSE}')\n",
    "                elif (i + 1) % verbose == 0:\n",
    "                    print(f'{i} | loss: {MSE}')\n",
    "            grad = 2/len(y) * np.dot((y_hat - y), X)\n",
    "            W -= self.learning_rate * grad\n",
    "            self.weight = W\n",
    "    \n",
    "    def get_coef(self):\n",
    "        return self.weight[1:]\n",
    "            \n",
    "        \n",
    "\n",
    "object = MyLineReg(10, 0.1)\n",
    "object.fit(X, y, 1)\n",
    "object.get_coef().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
      "0    1.191261 -0.308960  0.675137 -1.460501  0.053059 -1.886129  2.710794   \n",
      "1    1.071476 -1.424766 -1.109750 -0.457677  0.399997  1.587401 -1.547570   \n",
      "2   -0.045929  1.868603 -0.016568 -0.484258  1.089905 -1.147160  0.590744   \n",
      "3   -1.487154  2.220322  0.718332  1.682888 -0.420986 -0.054746  1.900832   \n",
      "4    0.344054  0.657763  0.348342 -0.417430 -0.589112  1.057814 -0.487705   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "995 -1.422254  0.576557 -0.646573 -0.756351 -0.127918  1.119575  1.687142   \n",
      "996  0.190500 -0.132634  0.709452  0.331980 -2.172670 -0.120381  0.513106   \n",
      "997 -0.326648 -0.062894  2.002427 -0.650657  1.592964 -0.395284  0.360226   \n",
      "998 -1.574342 -1.610263  0.407690  1.149487  1.466442 -0.338669 -2.059160   \n",
      "999  0.331964 -0.159202  0.510099 -0.586971  0.133761  2.344054  0.166339   \n",
      "\n",
      "        col_7     col_8     col_9    col_10    col_11    col_12    col_13  \n",
      "0   -1.716033  0.865290  0.138078 -0.063745 -2.104583 -0.476876  1.677116  \n",
      "1    0.323247  0.165859 -0.302097  0.203944 -0.212452  0.836991  0.368498  \n",
      "2    0.683325 -0.571184 -0.802199 -0.220114  0.034808  0.043829  0.955803  \n",
      "3   -0.101198  0.090042 -0.202924  0.340865  0.606237 -0.037008 -0.841048  \n",
      "4   -0.897830 -0.935596 -1.186993  1.074333 -0.069532 -0.177918 -0.912811  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "995 -1.081548 -0.955540  3.078881  0.881640  0.311250 -1.606446  0.203464  \n",
      "996 -0.435486  0.847422  1.107081 -0.259547 -0.974529 -0.535328 -0.090533  \n",
      "997 -0.307571  1.465211  0.658143  0.541321 -0.447878 -0.891543  0.069704  \n",
      "998  0.581000 -1.409216 -1.082018  0.798501  0.753190 -1.532598  0.269306  \n",
      "999 -0.572586  1.061785 -0.179530  1.236205  1.012943  0.805240 -0.036447  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
