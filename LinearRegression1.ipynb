{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
      "0    1.191261 -0.308960  0.675137 -1.460501  0.053059 -1.886129  2.710794   \n",
      "1    1.071476 -1.424766 -1.109750 -0.457677  0.399997  1.587401 -1.547570   \n",
      "2   -0.045929  1.868603 -0.016568 -0.484258  1.089905 -1.147160  0.590744   \n",
      "3   -1.487154  2.220322  0.718332  1.682888 -0.420986 -0.054746  1.900832   \n",
      "4    0.344054  0.657763  0.348342 -0.417430 -0.589112  1.057814 -0.487705   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "995 -1.422254  0.576557 -0.646573 -0.756351 -0.127918  1.119575  1.687142   \n",
      "996  0.190500 -0.132634  0.709452  0.331980 -2.172670 -0.120381  0.513106   \n",
      "997 -0.326648 -0.062894  2.002427 -0.650657  1.592964 -0.395284  0.360226   \n",
      "998 -1.574342 -1.610263  0.407690  1.149487  1.466442 -0.338669 -2.059160   \n",
      "999  0.331964 -0.159202  0.510099 -0.586971  0.133761  2.344054  0.166339   \n",
      "\n",
      "        col_7     col_8     col_9    col_10    col_11    col_12    col_13  \n",
      "0   -1.716033  0.865290  0.138078 -0.063745 -2.104583 -0.476876  1.677116  \n",
      "1    0.323247  0.165859 -0.302097  0.203944 -0.212452  0.836991  0.368498  \n",
      "2    0.683325 -0.571184 -0.802199 -0.220114  0.034808  0.043829  0.955803  \n",
      "3   -0.101198  0.090042 -0.202924  0.340865  0.606237 -0.037008 -0.841048  \n",
      "4   -0.897830 -0.935596 -1.186993  1.074333 -0.069532 -0.177918 -0.912811  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "995 -1.081548 -0.955540  3.078881  0.881640  0.311250 -1.606446  0.203464  \n",
      "996 -0.435486  0.847422  1.107081 -0.259547 -0.974529 -0.535328 -0.090533  \n",
      "997 -0.307571  1.465211  0.658143  0.541321 -0.447878 -0.891543  0.069704  \n",
      "998  0.581000 -1.409216 -1.082018  0.798501  0.753190 -1.532598  0.269306  \n",
      "999 -0.572586  1.061785 -0.179530  1.236205  1.012943  0.805240 -0.036447  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(\n",
    "    n_samples=1000, n_features=14, n_informative=10, noise=15, random_state=42\n",
    ")\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "X.columns = [f\"col_{col}\" for col in X.columns]\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | loss: 20621.089638778492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.55314269483333"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLineReg:\n",
    "    def __init__(self, n_iter, learning_rate):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\n",
    "            f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "        )\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
    "        #X.insert(0, 'ones', 1) #дополнение вектора фичей единичным столбцом\n",
    "        W = np.ones(X.shape[1]) #инициализация вектора весов соответствующей длины\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            y_hat = np.dot(X, W) #вычисление предсказаний\n",
    "            MSE = np.sum((y_hat - y) ** 2) / len(y) #вычисление функции потерь (в данном случае MSE)\n",
    "            if verbose and i % verbose == 0:\n",
    "                print(f'{i} | loss: {MSE}')\n",
    "            grad = 2/len(y) * np.dot((y_hat - y), X)\n",
    "            W -= self.learning_rate * grad\n",
    "            self.weight = W\n",
    "            # print(MSE)\n",
    "            # print(W)\n",
    "    \n",
    "    def get_coef(self):\n",
    "        return self.weight[1:]\n",
    "            \n",
    "        \n",
    "\n",
    "object = MyLineReg(50, 0.1)\n",
    "object.fit(X, y, 50)\n",
    "object.get_coef().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ones     col_0     col_1     col_2     col_3     col_4     col_5  \\\n",
      "0       1  1.191261 -0.308960  0.675137 -1.460501  0.053059 -1.886129   \n",
      "1       1  1.071476 -1.424766 -1.109750 -0.457677  0.399997  1.587401   \n",
      "2       1 -0.045929  1.868603 -0.016568 -0.484258  1.089905 -1.147160   \n",
      "3       1 -1.487154  2.220322  0.718332  1.682888 -0.420986 -0.054746   \n",
      "4       1  0.344054  0.657763  0.348342 -0.417430 -0.589112  1.057814   \n",
      "..    ...       ...       ...       ...       ...       ...       ...   \n",
      "995     1 -1.422254  0.576557 -0.646573 -0.756351 -0.127918  1.119575   \n",
      "996     1  0.190500 -0.132634  0.709452  0.331980 -2.172670 -0.120381   \n",
      "997     1 -0.326648 -0.062894  2.002427 -0.650657  1.592964 -0.395284   \n",
      "998     1 -1.574342 -1.610263  0.407690  1.149487  1.466442 -0.338669   \n",
      "999     1  0.331964 -0.159202  0.510099 -0.586971  0.133761  2.344054   \n",
      "\n",
      "        col_6     col_7     col_8     col_9    col_10    col_11    col_12  \\\n",
      "0    2.710794 -1.716033  0.865290  0.138078 -0.063745 -2.104583 -0.476876   \n",
      "1   -1.547570  0.323247  0.165859 -0.302097  0.203944 -0.212452  0.836991   \n",
      "2    0.590744  0.683325 -0.571184 -0.802199 -0.220114  0.034808  0.043829   \n",
      "3    1.900832 -0.101198  0.090042 -0.202924  0.340865  0.606237 -0.037008   \n",
      "4   -0.487705 -0.897830 -0.935596 -1.186993  1.074333 -0.069532 -0.177918   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "995  1.687142 -1.081548 -0.955540  3.078881  0.881640  0.311250 -1.606446   \n",
      "996  0.513106 -0.435486  0.847422  1.107081 -0.259547 -0.974529 -0.535328   \n",
      "997  0.360226 -0.307571  1.465211  0.658143  0.541321 -0.447878 -0.891543   \n",
      "998 -2.059160  0.581000 -1.409216 -1.082018  0.798501  0.753190 -1.532598   \n",
      "999  0.166339 -0.572586  1.061785 -0.179530  1.236205  1.012943  0.805240   \n",
      "\n",
      "       col_13  \n",
      "0    1.677116  \n",
      "1    0.368498  \n",
      "2    0.955803  \n",
      "3   -0.841048  \n",
      "4   -0.912811  \n",
      "..        ...  \n",
      "995  0.203464  \n",
      "996 -0.090533  \n",
      "997  0.069704  \n",
      "998  0.269306  \n",
      "999 -0.036447  \n",
      "\n",
      "[1000 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
